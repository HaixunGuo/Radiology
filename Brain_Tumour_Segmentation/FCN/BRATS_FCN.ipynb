{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TensorflowUtils as utils\n",
    "import read_BRATSParsingData as scene_parsing\n",
    "import datetime\n",
    "import BatchDatsetReader_3modalities as dataset\n",
    "from six.moves import xrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dirs = \"/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG\"\n",
    "test_dirs = \"/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Testing/HGG_LGG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS = tf.flags.FLAGS\n",
    "tf.flags.DEFINE_integer(\"batch_size\", 1, \"batch size for training\")\n",
    "tf.flags.DEFINE_string(\"logs_dir\", \"logs/\", \"path to logs directory\")\n",
    "tf.flags.DEFINE_string(\"data_dir\", data_dirs, \"path to dataset\")\n",
    "tf.flags.DEFINE_string(\"test_dir\", test_dirs, \"path to testset\")\n",
    "tf.flags.DEFINE_float(\"learning_rate\", 1e-4, \"Learning rate for Adam Optimizer\")\n",
    "tf.flags.DEFINE_string(\"model_dir\", \"./\", \"Path to vgg model mat\")\n",
    "tf.flags.DEFINE_bool('debug', False, \"Debug mode: True/ False\")\n",
    "tf.flags.DEFINE_string('mode', \"train\", \"Mode train/ test/ valid_visualize/ test_visualize\")\n",
    "MODEL_URL = 'http://www.vlfeat.org/matconvnet/models/beta16/imagenet-vgg-verydeep-19.mat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ITERATION = int(10000 + 1)\n",
    "NUM_OF_CLASSESS = 5\n",
    "IMAGE_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_net(weights, image):\n",
    "    layers = (\n",
    "        'conv1_1', 'relu1_1', 'conv1_2', 'relu1_2', 'pool1',\n",
    "\n",
    "        'conv2_1', 'relu2_1', 'conv2_2', 'relu2_2', 'pool2',\n",
    "\n",
    "        'conv3_1', 'relu3_1', 'conv3_2', 'relu3_2', 'conv3_3',\n",
    "        'relu3_3', 'conv3_4', 'relu3_4', 'pool3',\n",
    "\n",
    "        'conv4_1', 'relu4_1', 'conv4_2', 'relu4_2', 'conv4_3',\n",
    "        'relu4_3', 'conv4_4', 'relu4_4', 'pool4',\n",
    "\n",
    "        'conv5_1', 'relu5_1', 'conv5_2', 'relu5_2', 'conv5_3',\n",
    "        'relu5_3', 'conv5_4', 'relu5_4'\n",
    "    )\n",
    "\n",
    "    net = {}\n",
    "    current = image\n",
    "    for i, name in enumerate(layers):\n",
    "        kind = name[:4]\n",
    "        if kind == 'conv':\n",
    "            kernels, bias = weights[i][0][0][0][0]\n",
    "            # matconvnet: weights are [width, height, in_channels, out_channels]\n",
    "            # tensorflow: weights are [height, width, in_channels, out_channels]\n",
    "            kernels = utils.get_variable(np.transpose(kernels, (1, 0, 2, 3)), name=name + \"_w\")\n",
    "            bias = utils.get_variable(bias.reshape(-1), name=name + \"_b\")\n",
    "            current = utils.conv2d_basic(current, kernels, bias)\n",
    "        elif kind == 'relu':\n",
    "            current = tf.nn.relu(current, name=name)\n",
    "            if FLAGS.debug:\n",
    "                utils.add_activation_summary(current)\n",
    "        elif kind == 'pool':\n",
    "            current = utils.avg_pool_2x2(current)\n",
    "        net[name] = current\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(image, keep_prob):\n",
    "    \"\"\"\n",
    "    Semantic segmentation network definition\n",
    "    :param image: input image. Should have values in range 0-255\n",
    "    :param keep_prob:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    print(\"setting up vgg initialized conv layers ...\")\n",
    "    model_data = utils.get_model_data(FLAGS.model_dir, MODEL_URL)\n",
    "\n",
    "    mean = model_data['normalization'][0][0][0]\n",
    "    mean_pixel = np.mean(mean, axis=(0, 1))\n",
    "\n",
    "    weights = np.squeeze(model_data['layers'])\n",
    "\n",
    "    processed_image = utils.process_image(image, mean_pixel)\n",
    "\n",
    "    with tf.variable_scope(\"inference\"):\n",
    "        image_net = vgg_net(weights, processed_image)\n",
    "        conv_final_layer = image_net[\"conv5_3\"]\n",
    "\n",
    "        pool5 = utils.max_pool_2x2(conv_final_layer)\n",
    "\n",
    "        W6 = utils.weight_variable([7, 7, 512, 4096], name=\"W6\")\n",
    "        b6 = utils.bias_variable([4096], name=\"b6\")\n",
    "        conv6 = utils.conv2d_basic(pool5, W6, b6)\n",
    "        relu6 = tf.nn.relu(conv6, name=\"relu6\")\n",
    "        if FLAGS.debug:\n",
    "            utils.add_activation_summary(relu6)\n",
    "        relu_dropout6 = tf.nn.dropout(relu6, keep_prob=keep_prob)\n",
    "\n",
    "        W7 = utils.weight_variable([1, 1, 4096, 4096], name=\"W7\")\n",
    "        b7 = utils.bias_variable([4096], name=\"b7\")\n",
    "        conv7 = utils.conv2d_basic(relu_dropout6, W7, b7)\n",
    "        relu7 = tf.nn.relu(conv7, name=\"relu7\")\n",
    "        if FLAGS.debug:\n",
    "            utils.add_activation_summary(relu7)\n",
    "        relu_dropout7 = tf.nn.dropout(relu7, keep_prob=keep_prob)\n",
    "\n",
    "        W8 = utils.weight_variable([1, 1, 4096, NUM_OF_CLASSESS], name=\"W8\")\n",
    "        b8 = utils.bias_variable([NUM_OF_CLASSESS], name=\"b8\")\n",
    "        conv8 = utils.conv2d_basic(relu_dropout7, W8, b8)\n",
    "        # annotation_pred1 = tf.argmax(conv8, dimension=3, name=\"prediction1\")\n",
    "\n",
    "        # now to upscale to actual image size\n",
    "        deconv_shape1 = image_net[\"pool4\"].get_shape()\n",
    "        W_t1 = utils.weight_variable([4, 4, deconv_shape1[3].value, NUM_OF_CLASSESS], name=\"W_t1\")\n",
    "        b_t1 = utils.bias_variable([deconv_shape1[3].value], name=\"b_t1\")\n",
    "        conv_t1 = utils.conv2d_transpose_strided(conv8, W_t1, b_t1, output_shape=tf.shape(image_net[\"pool4\"]))\n",
    "        fuse_1 = tf.add(conv_t1, image_net[\"pool4\"], name=\"fuse_1\")\n",
    "\n",
    "        deconv_shape2 = image_net[\"pool3\"].get_shape()\n",
    "        W_t2 = utils.weight_variable([4, 4, deconv_shape2[3].value, deconv_shape1[3].value], name=\"W_t2\")\n",
    "        b_t2 = utils.bias_variable([deconv_shape2[3].value], name=\"b_t2\")\n",
    "        conv_t2 = utils.conv2d_transpose_strided(fuse_1, W_t2, b_t2, output_shape=tf.shape(image_net[\"pool3\"]))\n",
    "        fuse_2 = tf.add(conv_t2, image_net[\"pool3\"], name=\"fuse_2\")\n",
    "\n",
    "        shape = tf.shape(image)\n",
    "        deconv_shape3 = tf.stack([shape[0], shape[1], shape[2], NUM_OF_CLASSESS])\n",
    "        W_t3 = utils.weight_variable([16, 16, NUM_OF_CLASSESS, deconv_shape2[3].value], name=\"W_t3\")\n",
    "        b_t3 = utils.bias_variable([NUM_OF_CLASSESS], name=\"b_t3\")\n",
    "        conv_t3 = utils.conv2d_transpose_strided(fuse_2, W_t3, b_t3, output_shape=deconv_shape3, stride=8)\n",
    "\n",
    "        annotation_pred = tf.argmax(conv_t3, dimension=3, name=\"prediction\")\n",
    "\n",
    "    return tf.expand_dims(annotation_pred, dim=3), conv_t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(loss_val, var_list):\n",
    "    optimizer = tf.train.AdamOptimizer(FLAGS.learning_rate)\n",
    "    grads = optimizer.compute_gradients(loss_val, var_list=var_list)\n",
    "    if FLAGS.debug:\n",
    "        # print(len(var_list))\n",
    "        for grad, var in grads:\n",
    "            utils.add_gradient_summary(grad, var)\n",
    "    return optimizer.apply_gradients(grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(argv=None):\n",
    "    keep_probability = tf.placeholder(tf.float32, name=\"keep_probabilty\")\n",
    "    image = tf.placeholder(tf.float32, shape=[None, IMAGE_SIZE, IMAGE_SIZE, 3], name=\"input_image\")\n",
    "    annotation = tf.placeholder(tf.int32, shape=[None, IMAGE_SIZE, IMAGE_SIZE, 1], name=\"annotation\")\n",
    "\n",
    "    pred_annotation, logits = inference(image, keep_probability)\n",
    "    print(\"pred annotation : \", pred_annotation.shape)\n",
    "    print(\"logits : \", logits.shape)\n",
    "    tf.summary.image(\"input_image\", image, max_outputs=2)\n",
    "    tf.summary.image(\"ground_truth\", tf.cast(annotation, tf.uint8), max_outputs=2)\n",
    "    tf.summary.image(\"pred_annotation\", tf.cast(pred_annotation, tf.uint8), max_outputs=2)\n",
    "    loss = tf.reduce_mean((tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=tf.squeeze(annotation, squeeze_dims=[3]), name=\"entropy\")))\n",
    "    #loss = tf.reduce_mean((tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=annotation, name=\"entropy\")))\n",
    "    tf.summary.scalar(\"entropy\", loss)\n",
    "\n",
    "    trainable_var = tf.trainable_variables()\n",
    "    if FLAGS.debug:\n",
    "        for var in trainable_var:\n",
    "            utils.add_to_regularization_and_summary(var)\n",
    "    train_op = train(loss, trainable_var)\n",
    "\n",
    "    print(\"Setting up summary op...\")\n",
    "    summary_op = tf.summary.merge_all()\n",
    "\n",
    "    print(\"Setting up image reader...\")\n",
    "    #######train_records, valid_records = scene_parsing.read_dataset(FLAGS.data_dir)\n",
    "    ##print(len(train_records))\n",
    "    ##print(len(valid_records))\n",
    "    #######test_records = scene_parsing.read_test_dataset(FLAGS.test_dir)\n",
    "    ##print(len(test_records))\n",
    "    train_records = [{'T1c': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat473_0001/VSD.Brain.XX.O.MR_T1c.36577/VSD.Brain.XX.O.MR_T1c.36577.mha', 'annotation': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat473_0001/VSD.Brain_3more.XX.O.OT.42811/VSD.Brain_3more.XX.O.OT.42811.mha', 'T2': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat473_0001/VSD.Brain.XX.O.MR_T2.36578/VSD.Brain.XX.O.MR_T2.36578.mha', 'T1': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat473_0001/VSD.Brain.XX.O.MR_T1.36576/VSD.Brain.XX.O.MR_T1.36576.mha', 'FLAIR': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat473_0001/VSD.Brain.XX.O.MR_Flair.36575/VSD.Brain.XX.O.MR_Flair.36575.mha'}, {'T1c': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat296_0001/VSD.Brain.XX.O.MR_T1c.35946/VSD.Brain.XX.O.MR_T1c.35946.mha', 'annotation': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat296_0001/VSD.Brain_3more.XX.O.OT.42527/VSD.Brain_3more.XX.O.OT.42527.mha', 'T2': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat296_0001/VSD.Brain.XX.O.MR_T2.35945/VSD.Brain.XX.O.MR_T2.35945.mha', 'T1': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat296_0001/VSD.Brain.XX.O.MR_T1.35947/VSD.Brain.XX.O.MR_T1.35947.mha', 'FLAIR': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat296_0001/VSD.Brain.XX.O.MR_Flair.35944/VSD.Brain.XX.O.MR_Flair.35944.mha'}, {'T1c': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat171_1126/VSD.Brain.XX.O.MR_T1c.35633/VSD.Brain.XX.O.MR_T1c.35633.mha', 'annotation': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat171_1126/VSD.Brain_3more.XX.O.OT.42351/VSD.Brain_3more.XX.O.OT.42351.mha', 'T2': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat171_1126/VSD.Brain.XX.O.MR_T2.35632/VSD.Brain.XX.O.MR_T2.35632.mha', 'T1': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat171_1126/VSD.Brain.XX.O.MR_T1.35634/VSD.Brain.XX.O.MR_T1.35634.mha', 'FLAIR': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat171_1126/VSD.Brain.XX.O.MR_Flair.35631/VSD.Brain.XX.O.MR_Flair.35631.mha'}, {'T1c': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat135_0001/VSD.Brain.XX.O.MR_T1c.35575/VSD.Brain.XX.O.MR_T1c.35575.mha', 'annotation': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat135_0001/VSD.Brain_3more.XX.O.OT.42307/VSD.Brain_3more.XX.O.OT.42307.mha', 'T2': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat135_0001/VSD.Brain.XX.O.MR_T2.35574/VSD.Brain.XX.O.MR_T2.35574.mha', 'T1': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat135_0001/VSD.Brain.XX.O.MR_T1.35576/VSD.Brain.XX.O.MR_T1.35576.mha', 'FLAIR': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat135_0001/VSD.Brain.XX.O.MR_Flair.35573/VSD.Brain.XX.O.MR_Flair.35573.mha'}, {'T1c': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat419_0001/VSD.Brain.XX.O.MR_T1c.36290/VSD.Brain.XX.O.MR_T1c.36290.mha', 'annotation': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat419_0001/VSD.Brain_3more.XX.O.OT.42979/VSD.Brain_3more.XX.O.OT.42979.mha', 'T2': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat419_0001/VSD.Brain.XX.O.MR_T2.36289/VSD.Brain.XX.O.MR_T2.36289.mha', 'T1': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat419_0001/VSD.Brain.XX.O.MR_T1.36291/VSD.Brain.XX.O.MR_T1.36291.mha', 'FLAIR': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat419_0001/VSD.Brain.XX.O.MR_Flair.36288/VSD.Brain.XX.O.MR_Flair.36288.mha'}, {'T1c': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat374_0909/VSD.Brain.XX.O.MR_T1c.36136/VSD.Brain.XX.O.MR_T1c.36136.mha', 'annotation': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat374_0909/VSD.Brain_3more.XX.O.OT.42967/VSD.Brain_3more.XX.O.OT.42967.mha', 'T2': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat374_0909/VSD.Brain.XX.O.MR_T2.36135/VSD.Brain.XX.O.MR_T2.36135.mha', 'T1': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat374_0909/VSD.Brain.XX.O.MR_T1.36137/VSD.Brain.XX.O.MR_T1.36137.mha', 'FLAIR': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat374_0909/VSD.Brain.XX.O.MR_Flair.36134/VSD.Brain.XX.O.MR_Flair.36134.mha'}]\n",
    "    valid_records = [{'T1c': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat444_0104/VSD.Brain.XX.O.MR_T1c.36524/VSD.Brain.XX.O.MR_T1c.36524.mha', 'annotation': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat444_0104/VSD.Brain_3more.XX.O.OT.42775/VSD.Brain_3more.XX.O.OT.42775.mha', 'T2': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat444_0104/VSD.Brain.XX.O.MR_T2.36525/VSD.Brain.XX.O.MR_T2.36525.mha', 'T1': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat444_0104/VSD.Brain.XX.O.MR_T1.36523/VSD.Brain.XX.O.MR_T1.36523.mha', 'FLAIR': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat444_0104/VSD.Brain.XX.O.MR_Flair.36522/VSD.Brain.XX.O.MR_Flair.36522.mha'}, {'T1c': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat309_0462/VSD.Brain.XX.O.MR_T1c.40985/VSD.Brain.XX.O.MR_T1c.40985.mha', 'annotation': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat309_0462/VSD.Brain_3more.XX.O.OT.42545/VSD.Brain_3more.XX.O.OT.42545.mha', 'T2': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat309_0462/VSD.Brain.XX.O.MR_T2.40984/VSD.Brain.XX.O.MR_T2.40984.mha', 'T1': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat309_0462/VSD.Brain.XX.O.MR_T1.40986/VSD.Brain.XX.O.MR_T1.40986.mha', 'FLAIR': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat309_0462/VSD.Brain.XX.O.MR_Flair.40983/VSD.Brain.XX.O.MR_Flair.40983.mha'}, {'T1c': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat211_0001/VSD.Brain.XX.O.MR_T1c.35738/VSD.Brain.XX.O.MR_T1c.35738.mha', 'annotation': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat211_0001/VSD.Brain_3more.XX.O.OT.42895/VSD.Brain_3more.XX.O.OT.42895.mha', 'T2': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat211_0001/VSD.Brain.XX.O.MR_T2.35737/VSD.Brain.XX.O.MR_T2.35737.mha', 'T1': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat211_0001/VSD.Brain.XX.O.MR_T1.35739/VSD.Brain.XX.O.MR_T1.35739.mha', 'FLAIR': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat211_0001/VSD.Brain.XX.O.MR_Flair.35736/VSD.Brain.XX.O.MR_Flair.35736.mha'}, {'T1c': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat314_0001/VSD.Brain.XX.O.MR_T1c.41020/VSD.Brain.XX.O.MR_T1c.41020.mha', 'annotation': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat314_0001/VSD.Brain_3more.XX.O.OT.42569/VSD.Brain_3more.XX.O.OT.42569.mha', 'T2': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat314_0001/VSD.Brain.XX.O.MR_T2.41019/VSD.Brain.XX.O.MR_T2.41019.mha', 'T1': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat314_0001/VSD.Brain.XX.O.MR_T1.41021/VSD.Brain.XX.O.MR_T1.41021.mha', 'FLAIR': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat314_0001/VSD.Brain.XX.O.MR_Flair.41018/VSD.Brain.XX.O.MR_Flair.41018.mha'}, {'T1c': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat447_0199/VSD.Brain.XX.O.MR_T1c.41137/VSD.Brain.XX.O.MR_T1c.41137.mha', 'annotation': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat447_0199/VSD.Brain_3more.XX.O.OT.42785/VSD.Brain_3more.XX.O.OT.42785.mha', 'T2': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat447_0199/VSD.Brain.XX.O.MR_T2.41136/VSD.Brain.XX.O.MR_T2.41136.mha', 'T1': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat447_0199/VSD.Brain.XX.O.MR_T1.41138/VSD.Brain.XX.O.MR_T1.41138.mha', 'FLAIR': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat447_0199/VSD.Brain.XX.O.MR_Flair.41135/VSD.Brain.XX.O.MR_Flair.41135.mha'}]\n",
    "    test_records = [{'T1c': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Testing/HGG_LGG/brats_2013_pat0136_1/VSD.Brain.XX.O.MR_T1c.54271/VSD.Brain.XX.O.MR_T1c.54271.mha', 'T2': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Testing/HGG_LGG/brats_2013_pat0136_1/VSD.Brain.XX.O.MR_T2.54272/VSD.Brain.XX.O.MR_T2.54272.mha', 'T1': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Testing/HGG_LGG/brats_2013_pat0136_1/VSD.Brain.XX.O.MR_T1.54270/VSD.Brain.XX.O.MR_T1.54270.mha', 'FLAIR': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Testing/HGG_LGG/brats_2013_pat0136_1/VSD.Brain.XX.O.MR_Flair.54269/VSD.Brain.XX.O.MR_Flair.54269.mha'}, {'T1c': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Testing/HGG_LGG/brats_tcia_pat456_0127/VSD.Brain.XX.O.MR_T1c.40705/VSD.Brain.XX.O.MR_T1c.40705.mha', 'T2': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Testing/HGG_LGG/brats_tcia_pat456_0127/VSD.Brain.XX.O.MR_T2.40704/VSD.Brain.XX.O.MR_T2.40704.mha', 'T1': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Testing/HGG_LGG/brats_tcia_pat456_0127/VSD.Brain.XX.O.MR_T1.40706/VSD.Brain.XX.O.MR_T1.40706.mha', 'FLAIR': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Testing/HGG_LGG/brats_tcia_pat456_0127/VSD.Brain.XX.O.MR_Flair.40703/VSD.Brain.XX.O.MR_Flair.40703.mha'}, {'T1c': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Testing/HGG_LGG/brats_tcia_pat123_0360/VSD.Brain.XX.O.MR_T1c.40479/VSD.Brain.XX.O.MR_T1c.40479.mha', 'T2': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Testing/HGG_LGG/brats_tcia_pat123_0360/VSD.Brain.XX.O.MR_T2.40478/VSD.Brain.XX.O.MR_T2.40478.mha', 'T1': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Testing/HGG_LGG/brats_tcia_pat123_0360/VSD.Brain.XX.O.MR_T1.40480/VSD.Brain.XX.O.MR_T1.40480.mha', 'FLAIR': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Testing/HGG_LGG/brats_tcia_pat123_0360/VSD.Brain.XX.O.MR_Flair.40477/VSD.Brain.XX.O.MR_Flair.40477.mha'}, {'T1c': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Testing/HGG_LGG/brats_tcia_pat484_0386/VSD.Brain.XX.O.MR_T1c.40757/VSD.Brain.XX.O.MR_T1c.40757.mha', 'T2': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Testing/HGG_LGG/brats_tcia_pat484_0386/VSD.Brain.XX.O.MR_T2.40756/VSD.Brain.XX.O.MR_T2.40756.mha', 'T1': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Testing/HGG_LGG/brats_tcia_pat484_0386/VSD.Brain.XX.O.MR_T1.40758/VSD.Brain.XX.O.MR_T1.40758.mha', 'FLAIR': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Testing/HGG_LGG/brats_tcia_pat484_0386/VSD.Brain.XX.O.MR_Flair.40755/VSD.Brain.XX.O.MR_Flair.40755.mha'}, {'T1c': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Testing/HGG_LGG/brats_tcia_pat500_0465/VSD.Brain.XX.O.MR_T1c.41216/VSD.Brain.XX.O.MR_T1c.41216.mha', 'T2': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Testing/HGG_LGG/brats_tcia_pat500_0465/VSD.Brain.XX.O.MR_T2.41215/VSD.Brain.XX.O.MR_T2.41215.mha', 'T1': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Testing/HGG_LGG/brats_tcia_pat500_0465/VSD.Brain.XX.O.MR_T1.41217/VSD.Brain.XX.O.MR_T1.41217.mha', 'FLAIR': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Testing/HGG_LGG/brats_tcia_pat500_0465/VSD.Brain.XX.O.MR_Flair.41214/VSD.Brain.XX.O.MR_Flair.41214.mha'}, {'T1c': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Testing/HGG_LGG/brats_tcia_pat114_0115/VSD.Brain.XX.O.MR_T1c.40459/VSD.Brain.XX.O.MR_T1c.40459.mha', 'T2': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Testing/HGG_LGG/brats_tcia_pat114_0115/VSD.Brain.XX.O.MR_T2.40458/VSD.Brain.XX.O.MR_T2.40458.mha', 'T1': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Testing/HGG_LGG/brats_tcia_pat114_0115/VSD.Brain.XX.O.MR_T1.40460/VSD.Brain.XX.O.MR_T1.40460.mha', 'FLAIR': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Testing/HGG_LGG/brats_tcia_pat114_0115/VSD.Brain.XX.O.MR_Flair.40457/VSD.Brain.XX.O.MR_Flair.40457.mha'}, {'T1c': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Testing/HGG_LGG/brats_tcia_pat456_0043/VSD.Brain.XX.O.MR_T1c.40701/VSD.Brain.XX.O.MR_T1c.40701.mha', 'T2': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Testing/HGG_LGG/brats_tcia_pat456_0043/VSD.Brain.XX.O.MR_T2.40700/VSD.Brain.XX.O.MR_T2.40700.mha', 'T1': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Testing/HGG_LGG/brats_tcia_pat456_0043/VSD.Brain.XX.O.MR_T1.40702/VSD.Brain.XX.O.MR_T1.40702.mha', 'FLAIR': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Testing/HGG_LGG/brats_tcia_pat456_0043/VSD.Brain.XX.O.MR_Flair.40699/VSD.Brain.XX.O.MR_Flair.40699.mha'}, {'T1c': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Testing/HGG_LGG/brats_tcia_pat127_0001/VSD.Brain.XX.O.MR_T1c.40519/VSD.Brain.XX.O.MR_T1c.40519.mha', 'T2': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Testing/HGG_LGG/brats_tcia_pat127_0001/VSD.Brain.XX.O.MR_T2.40518/VSD.Brain.XX.O.MR_T2.40518.mha', 'T1': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Testing/HGG_LGG/brats_tcia_pat127_0001/VSD.Brain.XX.O.MR_T1.40520/VSD.Brain.XX.O.MR_T1.40520.mha', 'FLAIR': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Testing/HGG_LGG/brats_tcia_pat127_0001/VSD.Brain.XX.O.MR_Flair.40517/VSD.Brain.XX.O.MR_Flair.40517.mha'}, {'T1c': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Testing/HGG_LGG/brats_tcia_pat464_0001/VSD.Brain.XX.O.MR_T1c.40741/VSD.Brain.XX.O.MR_T1c.40741.mha', 'T2': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Testing/HGG_LGG/brats_tcia_pat464_0001/VSD.Brain.XX.O.MR_T2.40740/VSD.Brain.XX.O.MR_T2.40740.mha', 'T1': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Testing/HGG_LGG/brats_tcia_pat464_0001/VSD.Brain.XX.O.MR_T1.40742/VSD.Brain.XX.O.MR_T1.40742.mha', 'FLAIR': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Testing/HGG_LGG/brats_tcia_pat464_0001/VSD.Brain.XX.O.MR_Flair.40739/VSD.Brain.XX.O.MR_Flair.40739.mha'}, {'T1c': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Testing/HGG_LGG/brats_tcia_pat484_0214/VSD.Brain.XX.O.MR_T1c.40781/VSD.Brain.XX.O.MR_T1c.40781.mha', 'T2': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Testing/HGG_LGG/brats_tcia_pat484_0214/VSD.Brain.XX.O.MR_T2.40780/VSD.Brain.XX.O.MR_T2.40780.mha', 'T1': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Testing/HGG_LGG/brats_tcia_pat484_0214/VSD.Brain.XX.O.MR_T1.40782/VSD.Brain.XX.O.MR_T1.40782.mha', 'FLAIR': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Testing/HGG_LGG/brats_tcia_pat484_0214/VSD.Brain.XX.O.MR_Flair.40779/VSD.Brain.XX.O.MR_Flair.40779.mha'}] \n",
    "    #train_records = [{'T1c': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat473_0001/VSD.Brain.XX.O.MR_T1c.36577/VSD.Brain.XX.O.MR_T1c.36577.mha', 'annotation': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat473_0001/VSD.Brain_3more.XX.O.OT.42811/VSD.Brain_3more.XX.O.OT.42811.mha', 'T2': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat473_0001/VSD.Brain.XX.O.MR_T2.36578/VSD.Brain.XX.O.MR_T2.36578.mha', 'T1': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat473_0001/VSD.Brain.XX.O.MR_T1.36576/VSD.Brain.XX.O.MR_T1.36576.mha', 'FLAIR': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat473_0001/VSD.Brain.XX.O.MR_Flair.36575/VSD.Brain.XX.O.MR_Flair.36575.mha'}]\n",
    "    #valid_records = [{'T1c': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat444_0104/VSD.Brain.XX.O.MR_T1c.36524/VSD.Brain.XX.O.MR_T1c.36524.mha', 'annotation': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat444_0104/VSD.Brain_3more.XX.O.OT.42775/VSD.Brain_3more.XX.O.OT.42775.mha', 'T2': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat444_0104/VSD.Brain.XX.O.MR_T2.36525/VSD.Brain.XX.O.MR_T2.36525.mha', 'T1': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat444_0104/VSD.Brain.XX.O.MR_T1.36523/VSD.Brain.XX.O.MR_T1.36523.mha', 'FLAIR': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_tcia_pat444_0104/VSD.Brain.XX.O.MR_Flair.36522/VSD.Brain.XX.O.MR_Flair.36522.mha'}]\n",
    "    #test_records = [{'T1c': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Testing/HGG_LGG/brats_2013_pat0136_1/VSD.Brain.XX.O.MR_T1c.54271/VSD.Brain.XX.O.MR_T1c.54271.mha', 'T2': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Testing/HGG_LGG/brats_2013_pat0136_1/VSD.Brain.XX.O.MR_T2.54272/VSD.Brain.XX.O.MR_T2.54272.mha', 'T1': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Testing/HGG_LGG/brats_2013_pat0136_1/VSD.Brain.XX.O.MR_T1.54270/VSD.Brain.XX.O.MR_T1.54270.mha', 'FLAIR': '/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Testing/HGG_LGG/brats_2013_pat0136_1/VSD.Brain.XX.O.MR_Flair.54269/VSD.Brain.XX.O.MR_Flair.54269.mha'}]\n",
    "\n",
    "\n",
    "    print(\"Setting up dataset reader\")\n",
    "    image_options = {'resize': True, 'resize_size': IMAGE_SIZE}\n",
    "    if FLAGS.mode == 'train':\n",
    "        train_dataset_reader = dataset.BatchDatset(train_records, image_options)\n",
    "    validation_dataset_reader = dataset.BatchDatset(valid_records, image_options)\n",
    "    test_dataset_reader = dataset.TestDatset(test_records, image_options)\n",
    "      \n",
    "    sess = tf.Session()\n",
    "\n",
    "    print(\"Setting up Saver...\")\n",
    "    saver = tf.train.Saver()\n",
    "    summary_writer = tf.summary.FileWriter(FLAGS.logs_dir, sess.graph)\n",
    "    \n",
    "    print(\"Initializing variables...\")\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    ckpt = tf.train.get_checkpoint_state(FLAGS.logs_dir)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        print(\"Model restored...\")\n",
    "\n",
    "    if FLAGS.mode == \"train\":\n",
    "        for itr in xrange(MAX_ITERATION):\n",
    "            train_images, train_annotations = train_dataset_reader.next_batch(FLAGS.batch_size)\n",
    "            feed_dict = {image: train_images, annotation: train_annotations, keep_probability: 0.85}\n",
    "\n",
    "            sess.run(train_op, feed_dict=feed_dict)\n",
    "\n",
    "            if itr % 10 == 0:\n",
    "                train_loss, summary_str = sess.run([loss, summary_op], feed_dict=feed_dict)\n",
    "                print(\"Step: %d, Train_loss:%g\" % (itr, train_loss))\n",
    "                summary_writer.add_summary(summary_str, itr)\n",
    "\n",
    "            if itr % 500 == 0:\n",
    "                valid_images, valid_annotations = validation_dataset_reader.next_batch(FLAGS.batch_size)\n",
    "                valid_loss = sess.run(loss, feed_dict={image: valid_images, annotation: valid_annotations,\n",
    "                                                       keep_probability: 1.0})\n",
    "                print(\"%s ---> Validation_loss: %g\" % (datetime.datetime.now(), valid_loss))\n",
    "                saver.save(sess, FLAGS.logs_dir + \"model.ckpt\", itr)\n",
    "\n",
    "    elif FLAGS.mode == \"valid_visualize\":\n",
    "        print('validation dataset visualization')\n",
    "        valid_images, valid_annotations = validation_dataset_reader.get_random_batch(FLAGS.batch_size)\n",
    "        pred = sess.run(pred_annotation, feed_dict={image: valid_images, annotation: valid_annotations,\n",
    "                                                    keep_probability: 1.0})\n",
    "        ###valid_annotations = np.squeeze(valid_annotations, axis=3)\n",
    "        pred = np.squeeze(pred, axis=3)\n",
    "\n",
    "        for itr in range(FLAGS.batch_size):\n",
    "            utils.save_image(valid_images[itr].astype(np.double), FLAGS.logs_dir, name=\"inp_\" + str(5+itr))\n",
    "            utils.save_image(valid_annotations[itr].astype(np.double), FLAGS.logs_dir, name=\"gt_\" + str(5+itr))\n",
    "            utils.save_image(pred[itr].astype(np.double), FLAGS.logs_dir, name=\"pred_\" + str(5+itr))\n",
    "            print(\"Saved image: %d\" % itr)\n",
    "\n",
    "    elif FLAGS.mode == \"test_visualize\":\n",
    "        print('test dataset visualization')\n",
    "        test_images, test_annotations = test_dataset_reader.get_random_batch(FLAGS.batch_size)\n",
    "        pred = sess.run(pred_annotation, feed_dict={image: test_images, annotation: test_annotations,\n",
    "                                                    keep_probability: 1.0})\n",
    "        ###test_annotations = np.squeeze(test_annotations, axis=3)\n",
    "        ###pred = np.squeeze(pred, axis=3)\n",
    "\n",
    "        for itr in range(FLAGS.batch_size):\n",
    "            utils.save_image(test_images[itr].astype(np.double), FLAGS.logs_dir, name=\"inp_\" + str(5+itr))\n",
    "            utils.save_image(test_annotations[itr].astype(np.double), FLAGS.logs_dir, name=\"gt_\" + str(5+itr))\n",
    "            utils.save_image(pred[itr].astype(np.double), FLAGS.logs_dir, name=\"pred_\" + str(5+itr))\n",
    "            print(\"Saved image: %d\" % itr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting up vgg initialized conv layers ...\n",
      "WARNING:tensorflow:From <ipython-input-7-2f2b3dbd30ce>:64: calling argmax (from tensorflow.python.ops.math_ops) with dimension is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the `axis` argument instead\n",
      "pred annotation :  (?, ?, ?, 1)\n",
      "logits :  (?, ?, ?, 5)\n",
      "Setting up summary op...\n",
      "Setting up image reader...\n",
      "Setting up dataset reader\n",
      "Initializing Batch Dataset Reader...\n",
      "(930, 224, 224, 3)\n",
      "(930, 224, 224, 3)\n",
      "Initializing Batch Dataset Reader...\n",
      "(775, 224, 224, 3)\n",
      "(775, 224, 224, 3)\n",
      "Initializing Batch Dataset Reader...\n",
      "(1550, 224, 224, 3)\n",
      "Setting up Saver...\n",
      "Initializing variables...\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[7,7,512,4096]\n\t [[Node: inference/W6/Adam_1/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@inference/W6\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](inference/W6/Adam_1, inference/W6/Adam/Initializer/zeros)]]\n\nCaused by op 'inference/W6/Adam_1/Assign', defined at:\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2827, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-10-44cda3e31e6a>\", line 1, in <module>\n    tf.app.run()\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/platform/app.py\", line 48, in run\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\n  File \"<ipython-input-9-939d281a5a3a>\", line 20, in main\n    train_op = train(loss, trainable_var)\n  File \"<ipython-input-8-46fff4b18caf>\", line 8, in train\n    return optimizer.apply_gradients(grads)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py\", line 474, in apply_gradients\n    self._create_slots([_get_variable_for(v) for v in var_list])\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/adam.py\", line 137, in _create_slots\n    self._zeros_slot(v, \"v\", self._name)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py\", line 796, in _zeros_slot\n    named_slots[_var_key(var)] = slot_creator.create_zeros_slot(var, op_name)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/slot_creator.py\", line 174, in create_zeros_slot\n    colocate_with_primary=colocate_with_primary)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/slot_creator.py\", line 148, in create_slot_with_initializer\n    dtype)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/slot_creator.py\", line 67, in _create_slot_var\n    validate_shape=validate_shape)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 1203, in get_variable\n    constraint=constraint)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 1092, in get_variable\n    constraint=constraint)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 425, in get_variable\n    constraint=constraint)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 394, in _true_getter\n    use_resource=use_resource, constraint=constraint)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 805, in _get_single_variable\n    constraint=constraint)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\", line 213, in __init__\n    constraint=constraint)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\", line 346, in _init_from_args\n    validate_shape=validate_shape).op\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/state_ops.py\", line 276, in assign\n    validate_shape=validate_shape)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 57, in assign\n    use_locking=use_locking, name=name)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[7,7,512,4096]\n\t [[Node: inference/W6/Adam_1/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@inference/W6\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](inference/W6/Adam_1, inference/W6/Adam/Initializer/zeros)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[7,7,512,4096]\n\t [[Node: inference/W6/Adam_1/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@inference/W6\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](inference/W6/Adam_1, inference/W6/Adam/Initializer/zeros)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-44cda3e31e6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/platform/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[0;31m# Call the main function, passing through any arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0;31m# to the final program.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m   \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mflags_passthrough\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-939d281a5a3a>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(argv)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initializing variables...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mckpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_checkpoint_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[7,7,512,4096]\n\t [[Node: inference/W6/Adam_1/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@inference/W6\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](inference/W6/Adam_1, inference/W6/Adam/Initializer/zeros)]]\n\nCaused by op 'inference/W6/Adam_1/Assign', defined at:\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2827, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-10-44cda3e31e6a>\", line 1, in <module>\n    tf.app.run()\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/platform/app.py\", line 48, in run\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\n  File \"<ipython-input-9-939d281a5a3a>\", line 20, in main\n    train_op = train(loss, trainable_var)\n  File \"<ipython-input-8-46fff4b18caf>\", line 8, in train\n    return optimizer.apply_gradients(grads)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py\", line 474, in apply_gradients\n    self._create_slots([_get_variable_for(v) for v in var_list])\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/adam.py\", line 137, in _create_slots\n    self._zeros_slot(v, \"v\", self._name)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py\", line 796, in _zeros_slot\n    named_slots[_var_key(var)] = slot_creator.create_zeros_slot(var, op_name)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/slot_creator.py\", line 174, in create_zeros_slot\n    colocate_with_primary=colocate_with_primary)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/slot_creator.py\", line 148, in create_slot_with_initializer\n    dtype)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/slot_creator.py\", line 67, in _create_slot_var\n    validate_shape=validate_shape)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 1203, in get_variable\n    constraint=constraint)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 1092, in get_variable\n    constraint=constraint)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 425, in get_variable\n    constraint=constraint)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 394, in _true_getter\n    use_resource=use_resource, constraint=constraint)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 805, in _get_single_variable\n    constraint=constraint)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\", line 213, in __init__\n    constraint=constraint)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\", line 346, in _init_from_args\n    validate_shape=validate_shape).op\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/state_ops.py\", line 276, in assign\n    validate_shape=validate_shape)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 57, in assign\n    use_locking=use_locking, name=name)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/seonwhee/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[7,7,512,4096]\n\t [[Node: inference/W6/Adam_1/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@inference/W6\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](inference/W6/Adam_1, inference/W6/Adam/Initializer/zeros)]]\n"
     ]
    }
   ],
   "source": [
    "tf.app.run()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
