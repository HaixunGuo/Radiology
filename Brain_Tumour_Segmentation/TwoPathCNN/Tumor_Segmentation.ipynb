{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notice\n",
    "## This python code is an unofficial Tensorflow implementation of the model from following reference\n",
    "### Authors : Havaei,M.; Davy,A.; Warde-Farley,D.; Biard,A.; Courville,A.; Bengio,Y.; Pal,C.; Jodoin,P.M.; Larochelle,H. \n",
    "### Title : Brain tumor segmentation with Deep Neural Networks\n",
    "### Source : Med.Image Anal., 2017, 35, 18-31, Elsevier B.V, Netherlands\n",
    "###### The code has not been completed yet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import h5py\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from skimage import io, color, img_as_float\n",
    "from skimage.exposure import adjust_gamma\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from sklearn.feature_extraction.image import extract_patches_2d\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "from ipywidgets import interact, FloatSlider\n",
    "from myshow import myshow, myshow3d\n",
    "from TwoPathCNN import vanilla_CNN\n",
    "from BatchDatasetReader import BatchDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Cascaded_architecture(vanilla_CNN, object):\n",
    "    def CNN_for_INPUT_Cascade(self, x):\n",
    "        cascadedLayer = self.Defining_CNN(x, 65)\n",
    "        y_conv = self.Defining_CNN(x, 33, (\"InputCas\", cascadedLayer))\n",
    "        return y_conv\n",
    "    \n",
    "    def CNN_for_LOCAL_Cascade(self, x):\n",
    "        cascadedLayer = self.Defining_CNN(x, 56)\n",
    "        y_conv = self.Defining_CNN(x, 33, (\"LocalCas\", cascadedLayer))\n",
    "        return y_conv\n",
    "    \n",
    "    def CNN_for_MF_Cascade(self, x):\n",
    "        cascadedLayer = self.Defining_CNN(x, 53)\n",
    "        y_conv = self.Defining_CNN(x, 33, (\"MFCas\", cascadedLayer))\n",
    "        return y_conv\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Feeding_Data_and_Realizing_the_Model(_):\n",
    "    # data를 import한다.\n",
    "    img_T1 = sitk.ReadImage(\"/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_2013_pat0010_1/VSD.Brain.XX.O.MR_T1.54567/VSD.Brain.XX.O.MR_T1.54567.mha\")\n",
    "    img_T2 = sitk.ReadImage(\"/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_2013_pat0010_1/VSD.Brain.XX.O.MR_T2.54569/VSD.Brain.XX.O.MR_T2.54569.mha\")\n",
    "    img_FLAIR = sitk.ReadImage(\"/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_2013_pat0010_1/VSD.Brain.XX.O.MR_Flair.54566/VSD.Brain.XX.O.MR_Flair.54566.mha\")\n",
    "    img_T1c = sitk.ReadImage(\"/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_2013_pat0010_1/VSD.Brain.XX.O.MR_T1c.54568/VSD.Brain.XX.O.MR_T1c.54568.mha\")\n",
    "    img_GT = sitk.ReadImage(\"/home/seonwhee/Deep_Learning/Datasets/BRATS2015_Training/HGG/brats_2013_pat0010_1/VSD.Brain_3more.XX.O.OT.54571/VSD.Brain_3more.XX.O.OT.54571.mha\")\n",
    "\n",
    "    # 모델을 생성한다.\n",
    "    img_T1_Slice = img_T1[:,:,77]\n",
    "    img_T1c_Slice = img_T1c[:,:,77]\n",
    "    img_T2_Slice = img_T2[:,:,77]\n",
    "    img_FLAIR_Slice = img_FLAIR[:,:,77]\n",
    "    img_GT_Slice = img_GT[:,:,77]\n",
    "    imgVolume = sitk.JoinSeries(img_T1_Slice, img_T1c_Slice, img_T2_Slice, img_FLAIR_Slice)\n",
    "    width = imgVolume.GetWidth()\n",
    "    height = imgVolume.GetHeight()\n",
    "    depth = imgVolume.GetDepth()\n",
    "    X = tf.placeholder(tf.float32, shape=[None, width*height*depth])\n",
    "    ### NOTE: If you call this function often, you may want to (i) move the `np.pad()`\n",
    "    #### into the graph as `tf.pad()`, and (ii) replace `X_t` with a placeholder.\n",
    "    ###X = np.pad(X, (pad_amount, 0), 'constant')\n",
    "    ###X_t  = tf.convert_to_tensor(X)\n",
    "    ###output_t = tf.map_fn(window_func, tf.range(window_size))\n",
    "    ###output = sess.run(output_t)\n",
    "\n",
    "    \n",
    "    y_ = tf.placeholder(tf.float32, [None, width*height])\n",
    "\n",
    "    # Deep Neural Networks 그래프를 생성한다.\n",
    "    Graph = Cascaded_architecture()\n",
    "    y_conv = Graph.CNN_for_INPUT_Cascade(X)\n",
    "    \n",
    "    # loss와 optimizer를 정의한다.  ###############################################\n",
    "\n",
    "    # Cross Entropy를 비용함수(loss function)으로 정의하고, AdamOptimizer를 이용해서 비용 함수를 최소화한다.\n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "  \n",
    "    # 정확도를 측정한다.\n",
    "    correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FLAGS = tf.flags.FLAGS\n",
    "tf.flags.DEFINE_integer(\"batch_size\", 1, \"batch size for training\")\n",
    "tf.flags.DEFINE_string(\"logs_dir\", \"logs/\", \"path to logs directory\")\n",
    "tf.flags.DEFINE_string(\"data_dir\", \"Data_zoo/\", \"path to dataset\")\n",
    "tf.flags.DEFINE_float(\"learning_rate\", 1e-4, \"Learning rate for Adam Optimizer\")\n",
    "tf.flags.DEFINE_string(\"model_dir\", \"Model_zoo/\", \"Path to vgg model mat\")\n",
    "tf.flags.DEFINE_bool('debug', \"False\", \"Debug mode: True/ False\")\n",
    "tf.flags.DEFINE_string('mode', \"train\", \"Mode train/ test/ valid_visualize/ test_visualize\")\n",
    "\n",
    "#MAX_ITERATION = int(1e5 + 1)\n",
    "MAX_ITERATION = int(10000 + 1)\n",
    "NUM_OF_CLASSESS = 5\n",
    "IMAGE_SIZE = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(argv=None):\n",
    "    keep_probability = tf.placeholder(tf.float32, name=\"keep_probabilty\")\n",
    "    image = tf.placeholder(tf.float32, shape=[None, IMAGE_SIZE, IMAGE_SIZE, 3], name=\"input_image\")\n",
    "    annotation = tf.placeholder(tf.int32, shape=[None, IMAGE_SIZE, IMAGE_SIZE, 1], name=\"annotation\")\n",
    "\n",
    "    pred_annotation, logits = inference(image, keep_probability)\n",
    "    tf.summary.image(\"input_image\", image, max_outputs=2)\n",
    "    tf.summary.image(\"ground_truth\", tf.cast(annotation, tf.uint8), max_outputs=2)\n",
    "    tf.summary.image(\"pred_annotation\", tf.cast(pred_annotation, tf.uint8), max_outputs=2)\n",
    "    loss = tf.reduce_mean((tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits,\n",
    "                                                                          labels=tf.squeeze(annotation, squeeze_dims=[3]),\n",
    "                                                                          name=\"entropy\")))\n",
    "    tf.summary.scalar(\"entropy\", loss)\n",
    "\n",
    "    trainable_var = tf.trainable_variables()\n",
    "    if FLAGS.debug:\n",
    "        for var in trainable_var:\n",
    "            utils.add_to_regularization_and_summary(var)\n",
    "    train_op = train(loss, trainable_var)\n",
    "\n",
    "    print(\"Setting up summary op...\")\n",
    "    summary_op = tf.summary.merge_all()\n",
    "\n",
    "    print(\"Setting up image reader...\")\n",
    "    train_records, valid_records, test_records = scene_parsing.read_dataset(FLAGS.data_dir)\n",
    "    print(len(train_records))\n",
    "    print(len(valid_records))\n",
    "    print(len(test_records))\n",
    "\n",
    "    print(\"Setting up dataset reader\")\n",
    "    image_options = {'resize': True, 'resize_size': IMAGE_SIZE}\n",
    "    if FLAGS.mode == 'train':\n",
    "        train_dataset_reader = BatchDataset(train_records, image_options)\n",
    "    validation_dataset_reader = BatchDataset(valid_records, image_options)\n",
    "    test_dataset_reader = BatchDataset(test_records, image_options)\n",
    "      \n",
    "    config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    config.gpu_options.allocator_type = 'BFC'\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 0.40\n",
    "    sess = tf.Session(config=config)\n",
    "\n",
    "    print(\"Setting up Saver...\")\n",
    "    saver = tf.train.Saver()\n",
    "    summary_writer = tf.summary.FileWriter(FLAGS.logs_dir, sess.graph)\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    ckpt = tf.train.get_checkpoint_state(FLAGS.logs_dir)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        print(\"Model restored...\")\n",
    "\n",
    "    if FLAGS.mode == \"train\":\n",
    "        for itr in xrange(MAX_ITERATION):\n",
    "            train_images, train_annotations = train_dataset_reader.next_batch(FLAGS.batch_size)\n",
    "            feed_dict = {image: train_images, annotation: train_annotations, keep_probability: 0.85}\n",
    "\n",
    "            sess.run(train_op, feed_dict=feed_dict)\n",
    "\n",
    "            if itr % 10 == 0:\n",
    "                train_loss, summary_str = sess.run([loss, summary_op], feed_dict=feed_dict)\n",
    "                print(\"Step: %d, Train_loss:%g\" % (itr, train_loss))\n",
    "                summary_writer.add_summary(summary_str, itr)\n",
    "\n",
    "            if itr % 500 == 0:\n",
    "                valid_images, valid_annotations = validation_dataset_reader.next_batch(FLAGS.batch_size)\n",
    "                valid_loss = sess.run(loss, feed_dict={image: valid_images, annotation: valid_annotations,\n",
    "                                                       keep_probability: 1.0})\n",
    "                print(\"%s ---> Validation_loss: %g\" % (datetime.datetime.now(), valid_loss))\n",
    "                saver.save(sess, FLAGS.logs_dir + \"model.ckpt\", itr)\n",
    "\n",
    "    elif FLAGS.mode == \"valid_visualize\":\n",
    "        print('validation dataset visualization')\n",
    "        valid_images, valid_annotations = validation_dataset_reader.get_random_batch(FLAGS.batch_size)\n",
    "        pred = sess.run(pred_annotation, feed_dict={image: valid_images, annotation: valid_annotations,\n",
    "                                                    keep_probability: 1.0})\n",
    "        valid_annotations = np.squeeze(valid_annotations, axis=3)\n",
    "        pred = np.squeeze(pred, axis=3)\n",
    "\n",
    "        for itr in range(FLAGS.batch_size):\n",
    "            utils.save_image(valid_images[itr].astype(np.double), FLAGS.logs_dir, name=\"inp_\" + str(5+itr))\n",
    "            utils.save_image(valid_annotations[itr].astype(np.double), FLAGS.logs_dir, name=\"gt_\" + str(5+itr))\n",
    "            utils.save_image(pred[itr].astype(np.double), FLAGS.logs_dir, name=\"pred_\" + str(5+itr))\n",
    "            print(\"Saved image: %d\" % itr)\n",
    "\n",
    "    elif FLAGS.mode == \"test_visualize\":\n",
    "        print('test dataset visualization')\n",
    "        test_images, test_annotations = test_dataset_reader.get_random_batch(FLAGS.batch_size)\n",
    "        pred = sess.run(pred_annotation, feed_dict={image: test_images, annotation: test_annotations,\n",
    "                                                    keep_probability: 1.0})\n",
    "        test_annotations = np.squeeze(test_annotations, axis=3)\n",
    "        pred = np.squeeze(pred, axis=3)\n",
    "\n",
    "        for itr in range(FLAGS.batch_size):\n",
    "            utils.save_image(test_images[itr].astype(np.double), FLAGS.logs_dir, name=\"inp_\" + str(5+itr))\n",
    "            utils.save_image(test_annotations[itr].astype(np.double), FLAGS.logs_dir, name=\"gt_\" + str(5+itr))\n",
    "            utils.save_image(pred[itr].astype(np.double), FLAGS.logs_dir, name=\"pred_\" + str(5+itr))\n",
    "            print(\"Saved image: %d\" % itr)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
